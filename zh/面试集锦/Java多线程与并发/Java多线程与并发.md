# Java多线程与并发

## 进程和线程的区别

![](assert\2019-08-27_15-51-10.png)

![](assert\2019-08-27_15-52-20.png)

**区别总结：**

- 线程不能看做独立应用,而进程可看做独立应用
- 进程有独立的地址空间,相互不影响,线程只是进程的不同执行路径
- 线程没有独立的地址空间,多进程的程序比多线程程序健壮
- 进程的切换比线程的切换开销大

## Java进程和线程的关系

- Java对操作系统提供的功能进行封装,包括进程和线程
- 运行一个程序会产生一个进程,进程包含至少一个线程
- 每个进程对应一个JVM实例,多个线程共享JVM里的堆
-  Java采用单线程编程模型,程序会自动创建主线程
- 主线程可以创建子线程,原则上要后于子线程完成执行

## Thread中的start和run方法的区别

- 调用start()方法(内部调用一个start0()方法，是一个本地方法【C++实现】，由它创建一个线程)会创建一个新的子线程并启动 ，之后会使用子线程调用run()方法
- 调用run()方法只是Thread的一个普通方法的调用,直接调用run()方法不会启动子线程，实质还是由主线程调用

![](assert\2019-08-27_16-14-56.png)

## Thread和Runnable是什么关系

- Thread是实现了Runnable接口的类,使得run支持多线程
- 因类的单一继承原则,推荐多使用Runnable接口

![](assert\2019-08-27_16-29-01.png)

### 如何实现处理线程的返回值

1. 主线程等待法
2. 使用Thread类的join()阻塞当前线程以等待子线程处理完毕
3. 通过Callable接口实现:通过FutureTask Or 线程池获取

![](assert\2019-08-27_17-31-08.png)

![](assert\2019-08-27_17-36-13.png)

## 线程的状态

**六个状态**

**新建(New)** :创建后尚未启动的线程的状态

> 新创建了一个线程对象，但还没有调用start()方法

**运行(Runnable)**:包含Running(运行中)和Ready(就绪)

> Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”
>
> 线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得cpu 时间片后变为运行中状态（running）

**无限期等待(Waiting)**:不会被分配CPU执行时间,需要显式被唤醒

> 没有设置Timeout参数的Object.wait()方法
>
> 没有设置Timeout参数的Thread.join()方法
>
> LockSupport.park()方法
>
> 进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）

**限期等待(Timed Waiting)**:在一定时间后会由系统自动唤醒

> 该状态不同于WAITING，它可以在指定的时间内自行返回
>
> Thread.sleep(Timeout)方法
>
> 设置了Timeout参数的Object.wait(Timeout)方法
>
> 设置了Timeout参数的Thread.join(Timeout)方法
>
> LockSupport.parkNanos()方法
>
> LockSupport.parkUntil()方法

**阻塞(Blocked)**：等待获取排他锁

> 进入锁池等待,会竞争锁

**结束(Terminated)**:已终止线程的状态,线程已经结束执行

![](assert\2019-08-27_19-17-43.png)

> 参考: [Java线程状态切换以及核心方法](https://www.cnblogs.com/cowboys/p/9315331.html)

## sleep和wait的区别

**基本的差别**

- sleep是Thread类的方法, wait是Object类中定义的方法
-  sleep()方法可以在任何地方使用 
- wait()方法只能在synchronized方法或synchronized块中使用

**最主要的本质区别**

- Thread.sleep只会让出CPU(cpu时间片) ,不会导致锁行为的改变 (不会释放锁)

- Object.wait不仅让出CPU ,还会释放已经占有的同步资源锁(使用wait前先要获得锁，使用后需要释放锁)



## notify和notifyAll的区别

**两个概念**

> 锁池EntryList
>
> 等待池WaitSet
>
> 参考:[java对象在内存中的结构（HotSpot虚拟机）](https://www.cnblogs.com/duanxz/p/4967042.html)

**锁池**

 		假设线程A已经拥有了某个对象(不是类)的锁,而其它线程B、C想要调用这个对象的某个synchronized方法(或者块) ,由于B、C线程在进入对象的synchronized方法(或者块)之前必须先获得该对象锁的拥有权,而恰巧该对象的锁目前正被线程A所占用,此时B、C线程就会被阻塞,进入一个地方去等待锁的释放(竞争锁),这个地方便是该对象的锁池

**等待池**

​		假设线程A调用了某个对象的wait()方法,线程A就会释放该对象的锁,同时线程A就进入到了该对象的等待池中,**进入到等待池中的线程不会去竞争该对象的锁**。

**区别:**

- notifyAll 会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会
- notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会

## yield方法(线程礼让)

**概念**

​		当调用Thread.yield函数时,会给线程调度器一个当前愿意线程让出 CPU使用的暗示,但是线程调度器可能会忽略这个暗示。

> 让出cpu执行权（让出CPU后还会进行CPU的争夺），但是不会释放锁资源

## Thread.holdsLock方法(判断是否获取到某个对象的锁)

当且仅当当前线程持有指定对象上的监视器锁时才返回true 。

```java
Object o = new Object();
@Test
public void test1() throws Exception {
    new Thread(new Runnable() {
        @Override
        public void run() {
            synchronized(o) {
                System.out.println("child thread: holdLock: " + 
                    Thread.holdsLock(o));
            }
        }
    }).start();
    System.out.println("main thread: holdLock: " + Thread.holdsLock(o));
    Thread.sleep(2000);
}


main thread: holdLock: false
child thread: holdLock: true`
```

## 如何中断线程

- 目前使用的方法

	1. 调用interrupt() ,通知线程应该中断了
	2. 如果线程处于被阻塞状态,那么线程将立即退出被阻塞状态,并抛出一个InterruptedException异常
	3. 如果线程处于正常活动状态,那么会将该线程的中断标志设置为 true,被设置中断标志的线程将继续正常运行,不受影响

- 需要被调用的线程配合中断

	1. 在正常运行任务时,经常检查本线程的中断标志位,如果被设置了中断标志就自行停止线程。
	2. 如果线程处于正常活动状态,那么会将该线程的中断标志设置为 true,被设置中断标志的线程将继续正常运行,不受影响。


## 线程状态以及状态之间的转换

![](assert\2019-08-27_20-37-25.png)

## synchronized

**互斥锁的特性**

- **互斥性**:即在同一时间只允许一个线程持有某个对象锁,通过这种特性来实现多线程的协调机制,这样在同一时间只有一个线程对需要同步的代码块(复合操作)进行访问。互斥性也称为操作的原子性。
- **可见性**:必须确保在锁被释放之前,对共享变量所做的修改,对于随后获得该锁的另一个线程是可见的(即在获得锁时应获得最新共享变量的值) ,否则另一个线程可能是在本地缓存的某个副本上继续操作,从而引起不一致。

- synchronized锁的不是代码，锁的都是对象



**根据获取的锁的分类:获取对象锁和获取类锁获取对象锁的两种用法**

1. 同步代码块( synchronized (this) , synchronized (类实例对象)) ,锁是小括号()中的实例对象。
2. 同步非静态方法( synchronized method ) ,锁是当前对象的实例对象。
3. 同步静态方法( synchronized static method ) ,锁是当前对象的类实例对象。



### **对象锁和类锁的总结**

1. 有线程访问对象的同步代码块时,另外的线程可以访问该对象的非同步代码块
2. 若锁住的是同一个对象,一个线程在访问对象的同步代码块时,另一个访问对象同步方法的线程会被阻塞 
3. 若锁住的是同一个对象,一个线程在访问对象的同步方法时,另一个访问对象的同步代码块的线程会被阻塞
4. 若锁住的是同一个对象,一个线程在访问对象的同步代码块时,另一个访问对象同步方法的线程会被阻塞,反之亦然
5. 同一个类的不同对象的对象锁互不干扰
6. 类锁由于也是一种特殊的对象锁，因此表现和上述1,2, 3,4一致而由于一个类只有一把对象锁,所以同一个类的不同对象使用类锁将会是同步的;和对象锁互不干扰

### synchronized底层实现原理

![](assert\2019-08-28_14-18-31.png)

![](assert\2019-08-28_14-16-53.png)

![](assert\2019-08-28_14-17-21.png)

> Monitor :每个Java对象天生自带了一把看不见的锁

> 在 Java 中，每个对象都会有一个 monitor 对象，监视器。
>
> 1)        某一线程占有这个对象的时候，先判断monitor 的计数器是不是0，如果是0还没有线程占有，这个时候线程占有这个对象，并且对这个对象的monitor+1；如果不为0，表示这个线程已经被其他线程占有，这个线程等待。当线程释放占有权的时候，monitor-1；
>
> 2)        同一线程可以对同一对象进行多次加锁，+1，+1，重入性

![](assert\2019-08-28_14-21-58.png)

**什么是重入**

​	从互斥锁的设计上来说,当一个线程试图操作一个由其他线程持有的对象锁的临界资源时,将会处于阻塞状态,但当一个线程再次请求自己持有对象锁的临界资源时,这种情况属于重入

> synchronized是可重入的

**为什么会对synchronized嗤之以鼻**

> 早期版本中(jdk1.6之前), synchronized属于重量级锁,依赖于Mutex Lock实现 
>
> 线程之间的切换需要从用户态转换到核心态,开销较大
>
> ![](assert\2019-08-28_14-27-29.png)

**自旋锁**

> jdk1.4引入默认关闭   jdk1.6默认开启
>
> 许多情况下,共享数据的锁定状态持续时间较短,切换线程不值得
>
> 通过让线程执行忙循环等待锁的释放,不让出CPU
>
> 缺点:若锁被其他线程长时间占用,会带来许多性能上的开销

**自适应自旋锁**

> jdk1.6引入
>
> 自旋的次数不再固定
>
> 由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定

**锁消除**

> 更彻底的优化JIT编译时,对运行上下文进行扫描,去除不可能存在竞争的锁

**synchronized的四种状态**

> 无锁、偏向锁、轻量级锁、重量级锁
>
> 锁膨胀方向:无锁一偏向锁一轻量级锁—重量级锁

**偏向锁:**

- 减少同一线程获取锁的代价

- > 大多数情况下,锁不存在多线程竞争,总是由同一线程多次获得

- **核心思想**:如果**一个线程获得了锁,那么锁就进入偏向模式**,此时Mark Word的结构也变为偏向锁结构,当该线程再次请求锁时,无需再做任何同步操作,即获取锁的过程只需要检查Mark Word的锁标记位为偏向锁以及当前线程Id等于Mark Word的ThreadID即可,这样就省去了大量有关锁申请的操作。

  > 监视器使synchronized具有可重入性,偏向锁的优化使重入具有更高的效率

**轻量级锁**

- 轻量级锁是由偏向锁升级来的,偏向锁运行在**一个线程进入同步块**的情况下,当第二个线程加入**锁争用**的时候,**偏向锁就会升级为轻量级锁。**

  > 适应的场景:线程交替执行同步块

  > **如果说偏向锁是只允许一个线程获得锁，那么轻量级锁就是允许多个线程获得锁，但是只允许他们顺序拿锁，不允许出现竞争**，也就是**拿锁失败**的情况，**轻量级锁**的步骤如下：
  >
  > 1）线程1在执行同步代码块之前，JVM会先在当前线程的栈帧中创建一个空间用来存储锁记录，然后再把对象头中的Mark Word复制到该锁记录中，官方称之为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word 替换为指向锁记录的指针。如果成功，则获得锁，进入步骤3）。如果失败执行步骤2）
  >
  > 2）**线程自旋**，自旋成功则获得锁，进入步骤3）。**自旋失败，则膨胀成为重量级锁**，并把锁标志位变为10，线程阻塞进入步骤3）
  >
  > 3）锁的持有线程执行同步代码，执行完CAS替换Mark Word成功释放锁，如果CAS成功则流程结束，CAS失败执行步骤4）
  >
  > 4）CAS执行失败说明期间有线程尝试获得锁并自旋失败，轻量级锁升级为了重量级锁，此时释放锁之后，还要唤醒等待的线程

- 若存在**同一时间访问同一锁**的情况(**线程自旋,自旋失败，则膨胀成为重量级锁**),就会导致**轻量级锁膨胀为重量级锁**

**锁的内存语义**

> 当线程释放锁时, Java内存模型会把该线程对应的本地内存中的共享变量刷新到主内存中而当线程获取锁时, Java内存模型会把该线程对应的本地内存置为无效,从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。
>
> ![](assert\2019-08-28_14-44-31.png)

### 偏向锁、轻量级锁、重量级锁的汇总

![](assert\2019-08-28_14-45-38.png)

## synchronized和ReentrantLock的区别

**ReentrantLock (重入锁)**

- 位于java.util.concurrent.locks包
- 和CountDownLatch. FutureTask. 
- Semaphore一样基于AQS实现
- 能够实现比synchronized更细粒度的控制,如控制fairness(公平)
- 调用lock()之后,必须调用unlock()释放锁
- 性能未必比synchronized高,并且也是可重入的

**ReentrantLock公平性的设置**

- ReentrantLock fairLock = new ReentrantLock(true);

- 参数为true时，倾向于将锁赋予等待时间最久的线程

- > 公平锁:获取锁的顺序按先后调用lock方法的顺序(慎用)，先到者先得
  >
  > 非公平锁:抢占的顺序不一定，看运气 

- synchronized是非公平锁

**ReentrantLock将锁对象化**

- 判断是否有线程，或者某个特定线程,在排队等待获取锁   
- 带超时的获取锁的尝试
- 感知有没有成功获取锁     ReentrantLock.isLocked     ReentrantLock.isHeldByCurrentThread

### 总结

- synchronized是关键字属于Java提供的自动锁, ReentrantLock是类属于显示锁(按照加锁方式划分)
- ReentrantLock可以对获取锁的等待时间进行设置,避免死锁
-  ReentrantLock可以获取各种锁的信息
-  ReentrantLock可以灵活地实现多路通知
- 机制: sync操作Mark Word , lock调用Unsafe类的park(）方法

## 什么是Java内存模型

> happens-before原则是指令重排需要遵循的原则
>
> [参考资料:再有人问你Java内存模型是什么，就把这篇文章发给他](https://www.hollischuang.com/archives/2550)

### **Java内存模型------JMM**

​	Java内存模型(即Java Memory Model ,简称JMM)本身是一种抽象的概念,并不真实存在,它描述的是一组规则或规范,通过这组规范定义了程序中各个变量(包括实例字段,静态字段和构成数组对象的元素)的访问方式(是一组内存模型规范，目的是规范并发程序中共享变量的内存读写，屏蔽硬件和操作系统差异)。

![](assert\2019-08-28_15-12-50.png)

​    Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。

### JMM中的主内存

- 存储Java实例对象
- 包括成员变量、类信息、常量、静态变量等

- 属于数据共享的区域,多线程并发操作时会引发线程安全问题

### JMM中的工作内存

- 存储当前方法的所有本地变量信息,本地变量对其他线程不可见
- 字节码行号指示器、 Native方法信息
- 属于线程私有数据区域,不存在线程安全问题

### JMM与Java内存区域划分是不同的概念层次

- JMM描述的是一组规则,围绕原子性,有序性、可见性展开
- 相似点:存在共享区域和私有区域

> JVM中，主内存属于共享数据区域(线程共享)：包括堆、方法区（元数据空间）
>
> 工作内存属于私有区域(线程私有)：包括程序计数器、虚拟机栈、本地方法栈

### 主内存与工作内存的数据存储类型以及操作方式归纳

- 方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中

- 引用类型的本地变量:引用存储在工作内存中,实例存储在主内存中
- 成员变量、static变量、类信息均会被存储在主内存中 
- 主内存共享的方式是线程各拷贝一份数据到工作内存,操作完成后刷新回主内存

![](assert\2019-08-28_15-25-11.png)

### 指定重排需要遵循的happens-before八大原则

1. **程序次序规则**:一个线程内,按照代码顺序,书写在前面的操作先行发生于书写在后面的操作

   > 一个线程内保证串行语义的一致性

2. **锁定规则**:一个unLock操作先行发生于后面对同一个锁的lock操作;

3.  **volatile变量规则**:对一个变量的写操作先行发生于后面对这个变量的读操作;

4. **传递规则**:如果操作A先行发生于操作B,而操作B又先行发生于操作C ,则可以得出操作A先行发生于操作C;

5. **线程启动规则**: Thread对象的start()方法先行发生于此线程的每一个动作;

6. **线程中断规则**:对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生

7. **线程终结规则**:线程中所有的操作都先行发生于线程的终止检测,我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行;

8. **对象终结规则**:一个对象的初始化完成先行发生于他的finalize()方法的开始

> happens-before的概念
>
> 如果两个操作不满足上述任意一个happens-before规则,那么这两个操作就没有顺序的保障, JVM可以对这两个操作进行重排序;如果操作A happens-before操作B,那么操作A在内存上所做的操作对操作B都是可见的。

### volatile : JVM提供的轻量级同步机制

- 保证被volatile修饰的共享变量对所有线程总是立即可见的

  > 保证了可见性
  >
  > volatile变量为何立即可见?
  >
  > ​	1、当写一个volatile变量时, JMM会把该线程对应的工作内存中的全部共享变量值刷新到主内存中
  >
  > ​	2、当读取一个volatile变量时, JMM会把该线程对应的工作内存置为无效，  JMM会把当前线程用到的全部共享变量（不仅仅被volatile修饰的变量）从主存重新加载 。

- 禁止指令重排

  > 保证了有序性
  >
  > volatile如何禁止重排优化
  >
  > 内存屏障(Memory Barrier ) 
  >
  > 1、保证特定操作的执行顺序 
  >
  > 2、保证某些变量的内存可见性
  >
  > 3、通过插入内存屏障指令禁止在内存屏障前后的指令执行重排序优化

- volatile 不保证原子性

### 单例模式的双重检测与禁止指令重排实现

![](assert\2019-08-28_16-05-23.png)

![](assert\2019-08-28_16-06-10.png)

## volatile和synchronized的区别

1. volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的,需要从主存中读取; synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住直到该线程完成变量操作为止
2. volatile仅能使用在变量级别; synchronized则可以使用在变量、方法和类级别
3. volatile仅能实现变量的修改可见性和有序性,不能保证原子性;而 synchronized则可以保证变量修改的可见性、有序性、原子性 
4. volatile不会造成线程的阻塞; synchronized可能会造成线程的阻塞 
5. volatile标记的变量不会被编译器优化; synchronized标记的变量可以被编译器优化

## CAS ( Compare and Swap)

- 一种高效实现线程安全性的方法
- 支持原子更新操作,适用于计数器,序列发生器等场景
- 属于乐观锁机制,号称lock-free 
- CAS操作失败时由开发者决定是继续尝试,还是执行别的操作

**CAS思想**

> 包含三个操作数--内存位置(V)、预期原值(A)和新值(B)

**CAS多数情况下对开发者来说是透明的**（了解）

- J.U.C的atomic包(典型乐观锁实现)提供了常用的原子性数据类型以及引用、数组等相关原子类型和更新操作工具,是很多线程安全程序的首选
-  Unsafe类虽提供CAS服务,但因能够操纵任意内存地址读写而有隐患
- Java9以后,可以使用Variable Handle API来替代Unsafe

**缺点**

> 若循环时间长,则开销很大 
>
> 只能保证一个共享变量的原子操作
>
> ABA问题  解决: AtomicStampedReference

## 面试 LockSupport.park()会释放锁资源吗？

> https://www.cnblogs.com/tong-yuan/p/11768904.html

### Thread.sleep()和Object.wait()的区别

首先，我们先来看看Thread.sleep()和Object.wait()的区别，这是一个烂大街的题目了，大家应该都能说上来两点。

（1）Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁；

（2）Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去；

（3）Thread.sleep()到时间了会自动唤醒，然后继续执行；

（4）Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒；

（5）Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；

其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。

### Thread.sleep()和Condition.await()的区别

我们再来看看Thread.sleep()和Condition.await()的区别。

其实，这个题目和上面的题目比较类似，因为本来Object.wait()和Condition.await()的原理就比较类似，可以参考之前彤哥写的《死磕 java线程系列之线程的生命周期》之篇文章。

这个题目的回答思路跟Object.wait()是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。

实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程，可以参考之前彤哥写的《死磕 java同步系列之ReentrantLock源码解析（二）——条件锁》这篇文章。

看到这里，今天开篇提的那个问题是不是就有答案了呢【本文由公从号“彤哥读源码”原创】？

### Thread.sleep()和LockSupport.park()的区别

LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。

（1）从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且**都不会释放当前线程占有的锁资源**；

（2）Thread.sleep()没法从外部唤醒，只能自己醒过来；

（3）LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒；

（4）Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出；

（5）LockSupport.park()方法不需要捕获中断异常；

（6）Thread.sleep()本身就是一个native方法；

（7）LockSupport.park()底层是调用的Unsafe的native方法；

### Object.wait()和LockSupport.park()的区别

二者都会阻塞当前线程的运行，他们有什么区别呢？经过上面的分析相信你一定很清楚了，真的吗？往下看！

（1）Object.wait()方法需要在synchronized块中执行；

（2）LockSupport.park()可以在任意地方执行；

（3）Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出；

（4）LockSupport.park()不需要捕获中断异常【本文由公从号“彤哥读源码”原创】；

（5）Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容；

（6）LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容；

（7）**如果在wait()之前执行了notify()会怎样？抛出IllegalMonitorStateException异常**；

（8）**如果在park()之前执行了unpark()会怎样？线程不会被阻塞，直接跳过park()，继续执行后续内容；**

最后两点是不是没想到？！

其实，在《死磕 java线程系列之自己动手写一个线程池（续）》这篇文章里代码注释里稍微提到过unpark()这个方法，它先执行，则后续的park()方法将不再起作用。

park()/unpark()底层的原理是“**二元信号量**”，你可以把它相像成只有一个许可证的Semaphore，只不过这个信号量在重复执行unpark()的时候也不会再增加许可证，最多只有一个许可证。

关于信号量的内容，可以参考《死磕 java同步系列之Semaphore源码解析》这篇文章。

### LockSupport.park()会释放锁资源吗？

不会，它只负责阻塞当前线程，释放锁资源实际上是在Condition的await()方法中实现的。

![](assert\2020-01-29_10-05-28.png)

## Java线程池

**利用Executors创建不同的线程池满足不同场景的需求**

1. newFixedThreadPool(int nThreads)

   > 指定工作线程数量的线程池
   >
   > 弊端： 阻塞队列是LinkedBlockingQueue，是一个无界队列，最大值是2^31-1,当有大量任务时容易导致内存爆满产生OOM异常

2. newCachedThreadPool()

   > 处理大量短时间工作任务的线程池
   >
   > (1)试图缓存线程并重用,当无缓存线程可用时,就会创建新的工作线程
   >
   > (2)如果线程闲置的时间超过阈值,则会被终止并移出缓存
   >
   > (3)系统长时间闲置的时候,不会消耗什么资源
   >
   > 弊端：核心线程数是0，最大线程数是2^31-1,阻塞队列是SynchronousQueue，没有存储功能，当有大量任务时会产生大量线程，引发内存OOM

3. newSingleThreadExecutor()

   > 创建唯一的工作者线程来执行任务,如果线程异常结束,会有另一个线程取代它
   >
   > 弊端： 阻塞队列是LinkedBlockingQueue，是一个无界队列，最大值是2^31-1,当有大量任务时容易导致内存爆满产生OOM异常

4. newSingleThreadScheduledExecutor()与newScheduledThreadPool(int corePoolSize)

   > 定时或者周期性的工作调度,两者的区别在于单一工作线程还是多个线程

5. newWorkStealingPool()

   > jdk8提供 内部会构建ForkJoinPool ,利用working-stealing算法,并行地处理任务,不保证处理顺序

![](assert\2019-08-28_16-32-31.png)

![](assert\2019-08-28_16-37-45.png)

![](assert\2019-08-28_16-50-01.png)

 ![](assert\2019-08-28_16-53-41.png)

![](assert\2019-08-28_16-54-23.png)

![](assert\2019-08-28_16-55-39.png)

> Java高并发程序设计113页

### 构造函数

先来看构造函数：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();　　　　　// 注意 workQueue, threadFactory, handler 是不可以为null 的，为空会直接抛出错误
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

1. **corePoolSize 核心线程数：**表示核心线程池的大小。当提交一个任务时，如果当前核心线程池的线程个数没有达到 corePoolSize，则会创建新的线程来执行所提交的任务，即使当前核心线程池有空闲的线程。如果当前核心线程池的线程个数已经达到了corePoolSize，则不再重新创建线程。如果调用了 `prestartCoreThread() `( 创一个空闲任务线程等待任务的到达 )或者 `prestartAllCoreThreads()`(创建核心线程池数量的空闲任务线程等待任务的到达)，线程池一个或所有的核心线程都会被创建并且启动，否则仅在执行新任务时启动核心线程。若 corePoolSize == 0，则任务执行完之后，没有任何请求进入时，空闲时间后销毁线程池的线程。若 corePoolSize > 0，即使本地任务执行完毕，核心线程也不会被销毁。corePoolSize 其实可以理解为可保留的空闲线程数。
2. **maximumPoolSize：** 表示线程池能够容纳同时执行的最大线程数。如果当阻塞队列已满时，并且当前线程池线程个数没有超过 maximumPoolSize 的话，就会创建新的线程来执行任务。注意 maximumPoolSize >= 1 必须大于等于 1。maximumPoolSize == corePoolSize ，即是固定大小线程池。**实际上最大容量是由 CAPACITY 控制**。
3. **keepAliveTime：** 线程空闲时间。当空闲时间达到 keepAliveTime值时，线程会被销毁，直到只剩下 corePoolSize 个线程为止，避免浪费内存和句柄资源。默认情况，当线程池的线程数 > corePoolSize 时，keepAliveTime 才会起作用。但当 ThreadPoolExecutor 的 allowCoreThreadTimeOut 变量设置为 true 时，核心线程超时后会被回收。
4. **unit：**时间单位。为 keepAliveTime 指定时间单位。
5. **workQueue** 缓存队列。当请求的线程数 > corePoolSize 时，线程进入 BlockingQueue 阻塞队列。可以使用 ArrayBlockingQueue, LinkedBlockingQueue, SynchronousQueue, PriorityBlockingQueue。
6. **threadFactory** 创建线程的工程类，新线程使用ThreadFactory创建。 如果未另行指定，则使用Executors.defaultThreadFactory默认工厂，使其全部位于同一个ThreadGroup中，并且具有相同的NORM_PRIORITY优先级和非守护进程状态 。可以通过指定线程工厂为每个创建出来的线程设置更有意义的名字，如果出现并发问题，也方便查找问题原因
7. **handler** 执行拒绝策略的对象。当线程池的阻塞队列已满和指定的线程都已经开启，说明当前线程池已经处于饱和状态了，那么就需要采用一种策略来处理这种情况。采用的策略有这几种：

- - AbortPolicy： 直接拒绝所提交的任务，并抛出 **RejectedExecutionException** 异常，默认策略；
  - CallerRunsPolicy：只用调用者所在的线程来执行任务；
  - DiscardPolicy：不处理直接丢弃掉任务；
  - DiscardOldestPolicy：丢弃掉阻塞队列中存放时间最久的任务，执行当前任务

**设：我们有一个coreSize=10，maxSize=20，keepAliveTime=60s，queue=40**
1、默认情况下线程池初始化时里面没有任何线程，在执行新任务时启动核心线程。

`prestartCoreThread() `( 创一个空闲任务线程等待任务的到达 )

`prestartAllCoreThreads()`(创建核心线程池数量的空闲任务线程等待任务的到达)

2、当有一个任务提交到线程池就创建第一个线程。
3、若继续提交任务，当前核心线程池的线程个数小于 corePoolSize，则会创建新的线程来执行所提交的任务，即使当前核心线程池有空闲的线程。【**预热阶段**】
4、若继续提交任务，则将任务缓存到queue中排队等待。
5、若继续提交任务，且queue也满了，则新建线程，并将**最新的**任务优先提交给新线程处理。
6、若继续提交任务，如果此时已达到最大线程数(20)，就会触发线程池的拒绝策略。
8、一旦有任何线程空闲下来就会从queue中消费任务，直到queue中任务被消费完。
9、当总忙碌线程个数不超过coreSize时，闲暇线程休息keepAliveTime过后会被销毁。
10、而池中一直保留coreSize个线程存活。 

![](assert\2019-08-28_16-57-35.png)

#### 线程池的状态

- RUNNING :能接受新提交的任务,并且也能处理阻塞队列中的任务 

- SHUTDOWN :不再接受新提交的任务,但可以处理存量任务 

- STOP:不再接受新提交的任务,也不处理存量任务 

  > (1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。
  >
  > (2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -> STOP。

- TIDYING :所有的任务都已终止 

  > (1) 状态说明：当所有的任务已终止，任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若 用户想在线程池变为TIDYING时，进行相应的处理；可以通过重写terminated()函数来实现。 
  >
  > (2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -> TIDYING。 当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -> TIDYING。

- TERMINATED : terminated()方法执行完后进入该状态


![](assert\2019-08-28_17-02-20.png)

![](assert\2019-08-28_17-03-54.png)

![](assert\2019-08-28_17-04-54.png)

## 解决哈希冲突的三种方法

### 	链地址法(拉链法)

>  HashMap，HashSet其实都是采用的拉链法来解决哈希冲突的，就是在每个位桶实现的时候，我们采用链表（jdk1.8之后采用链表+红黑树）的数据结构来去存取发生哈希冲突的输入域的关键字 
>
> 拉链法的优点
>
> 与开放定址法相比，拉链法有如下几个优点：
>
> ①拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；
>
> ②由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况；
>
> ③开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间；
>
> ④在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。
>
>  
>
> 拉链法的缺点
>
> 指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。
> 

### 	开放定址法

> 从发生冲突的那个单元起，按照一定的次序，从哈希表中找到一个空闲的单元。然后把发生冲突的元素存入到该单元的一种方法。开放定址法需要的表长度要大于等于所需要存放的元素。
>  在开放定址法中解决冲突的方法有：线行探查法、平方探查法、双散列函数探查法。
>
> 
>
>  开放定址法的缺点： 在于删除元素的时候不能真的删除，否则会引起查找错误，只能做一个特殊标记。只到有下个元素插入才能真正删除该元素。

1. 线性探测

>  线行探查法是开放定址法中最简单的冲突处理方法，它从发生冲突的单元起，依次判断下一个单元是否为空，当达到最后一个单元时，再从表首依次判断。直到碰到空闲的单元或者探查完全部单元为止。 比如ThreadLocal

2. 平方探测

> 平方探查法即是发生冲突时，用发生冲突的单元d[i], 加上 1²、 2²等。即d[i] + 1²，d[i] + 2², d[i] + 3²...直到找到空闲单元。
> 在实际操作中，平方探查法不能探查到全部剩余的单元。不过在实际应用中，能探查到一半单元也就可以了。若探查到一半单元仍找不到一个空闲单元，表明此散列表太满，应该重新建立

3. 双散列函数探测

> 这种方法使用两个散列函数hl和h2。其中hl和前面的h一样，以关键字为自变量，产生一个0至m—l之间的数作为散列地址；h2也以关键字为自变量，产生一个l至m—1之间的、并和m互素的数(即m不能被该数整除)作为探查序列的地址增量(即步长)，探查序列的步长值是固定值l；对于平方探查法，探查序列的步长值是探查次数i的两倍减l；对于双散列函数探查法，其探查序列的步长值是同一关键字的另一散列函数的值

4. 伪随机探测

>  di=伪随机数序列；具体实现时，应建立一个伪随机数发生器，（如i=(i+p) % m），生成一个位随机序列，并给定一个随机数做起点，每次去加上这个伪随机数++就可以了。 

### 	再哈希法

> 再哈希法其实很简单，就是再使用哈希函数去散列一个输入的时候，输出是同一个位置就再次哈希，直至不发生冲突位置
>
> 缺点：每次冲突都要重新哈希，计算时间增加。

### 	建立公共溢出区

> 将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。



## 谈谈Java中的ThreadLocal

>  	ThreadLocal一般称为**线程本地变量，**它是一种特殊的线程绑定机制，将变量与线程**绑定**在一起，为每一个线程维护一个独立的变量副本。通过ThreadLocal可以将对象的可见范围限制在同一个线程内。 ThreadLocal可以理解为将对象的作用范围限制在一个**线程上下文**中，使得变量的作用域为“**线程级**”。  



## AQS原理

> ​       AQS是AbstractQueuedSynchronizer的简称。AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，如下图所示。AQS为一系列同步器依赖于一个单独的原子变量（state）的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。鉴于此，本类中的其他方法执行所有的排队和阻塞机制。子类也可以维护其他的state变量，但是为了保证同步，必须原子地操作这些变量。

>  AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。
>    不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：
>
> > - isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
> > - tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
> > - tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
> > - tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
> > - tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

![](assert\2019-09-30_09-48-05.png)

### 为什么 AQS 需要一个虚拟 head 节点

> 事情要从 Node 类的 waitStatus 变量说起，简称 ws。每个节点都有一个 ws 变量，用于这个节点状态的一些标志。初始状态是 0。如果被取消了，节点就是 1，那么他就会被 AQS 清理。
>
> 还有一个重要的状态：SIGNAL —— -1，表示：当当前节点释放锁的时候，需要唤醒下一个节点。
>
> 所有，每个节点在休眠前，都需要将前置节点的 ws 设置成 SIGNAL。**否则自己永远无法被唤醒**。
>
> 而为什么需要这么一个 ws 呢？—— 防止重复操作。假设，当一个节点已经被释放了，而此时另一个线程不知道，再次释放。这时候就错误了。
>
> 所以，需要一个变量来保证这个节点的状态。而且修改这个节点，必须通过 CAS 操作保证线程安全。
>
> So，回到我们之前的问题：为什么要创建一个虚拟节点呢？
>
> 每个节点都必须设置前置节点的 ws 状态为 SIGNAL，所以必须要一个前置节点，而这个前置节点，实际上就是当前持有锁的节点。
>
> 问题在于有个边界问题：**第一个节点怎么办？**他是没有前置节点的。
>
> > 那就创建一个假的。
>
> 这就是为什么要创建一个虚拟节点的原因。
>
> 总结下来就是：**每个节点都需要设置前置节点的 ws 状态（这个状态为是为了保证数据一致性），而第一个节点是没有前置节点的，所以需要创建一个虚拟节点**。

> [并发编程——详解 AQS CLH 锁](<https://www.jianshu.com/p/4682a6b0802d>)
>
> [AQS(一) 对CLH队列的增强](https://www.cnblogs.com/faunjoe88/p/8269285.html)